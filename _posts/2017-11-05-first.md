---
layout: post
title: Visualizing Learning rate vs Batch size
subtitle: Neural Nets basics using Fast.ai tools 
---

If you are reading this post chances are you are a relative of mine or you want to get insights about neural nets.
 
Only one week since beginning of the -unique in its kind- **Jeremy Howard and Rachel Thomas' [Fastai](http://www.fast.ai/) international course 1v2**. The amount of information and code flowing is already overwhelming, and it's just the beginning.

I know that if I wait for the dust to settle and everything to be tidy in my head I will contribute and post when I am 90 year old. So, my plan, **if I think an idea can help anyone that is just a small step behind me I will post it.** 

Fast.ai deep learning first lesson uses the famous Kaggle competition dataset "dogs vs. cats" to show binary classification with pretrained convnets. Even if you think "I have done that already" I advise you to watch the video in some months from now when it becomes public. Because I also "have done that already" but the approaches, tips, and opinions Jeremy Howard gives as well as the tools are... well, just as intended, both cutting edge and fully usable. 

One of the very remarkable tools gives **the possibility to find the optimal learning rate** for a given dataset. Being learning rate both extremely important and quite difficult to tune (before this) I found this great news. This is how this tool looks like in action:

<img src="/img/loss_vs_lr.PNG" align="center"/>

The plot shows **Loss vs. Learning rate** for the dataset. Its easy to spot an optimal learning rate before the curve flattens. 

Simple and useful, isn't it? But also made me think how insightful it would be to **use the tool  to visualize the famous relationship between learning rate and batch size.**

For the ones unaware, **general rule is "bigger batch size bigger learning rate"**. This is just logical because bigger batch size means more confidence in the direction of your "descent" of the error surface while the smaller a batch size is the closer you are to "stochastic" descent (batch size 1) that also works but where direction of individual "steps" is more... well, more stochastic. 

So... let's see how it looks like. In this case it is true that a picture is worth one thousand words:

<img src="/img/learning_rate_vs_batch_size_g.PNG" align="center"/>

There you have it, **the relationship between learning rate error plotted using  batches from 64 to 8** for the "cats vs. dogs" dataset.

As expected bigger batch size shows bigger optimal learning rate, but I find it interesting to see how those curves relate to each other. Also worth noting the increasing noise of the relationship as batch size decreases.

So, that was it, my first post and hopefully not the last one, **hope you enjoyed it!**

