---
layout: post
title: Visualizing Learning rate vs Batch size
subtitle: Neural Nets basics 
---

 If you are reading this post biggest chances are, you are a relative of mine or you want to get insights about neural nets.
 
 Only one week passed since the beginning of the -unique in its kind- Jeremy Howard and Rachel Thomas' [Fastai] (http://www.fast.ai/) international course 1.v2. The amount of information and code flowing is so overwhelming that it is hard to choose what to focus on. 

 I know myself and if I wait for the dust to settle and everything be tidy in my head I will contribute and post when I am 90 year old. So, my plan, if I think an idea can help anyone that is just a small step behind me I will post it. At least it will be a place for me to keep all those small insights in one place.

 So... fast.ai first lesson focuses on being able to classify the famous Kaggle competition dataset "dogs vs. cats" with pretrained convnets. Even if you think "yes, I have done that already", I advise you to watch the video in some months from now, when it becomes public. Because I also "have done that already" but the approaches, tips, and opinions Jeremy Howard gives as well as the tools are... well, just as intended, cutting edge.  

 One of the very remarcables tools gave the posibility to find the optimal learning rate for a given dataset. Being learning rate both extremly important and quite difficult to tune (before this) I found this great news. This is how this tool looks like:

!(https://github.com/miguel-data-sc/miguel-data-sc.github.io/blob/master/img/loss_vs_lr.PNG)


There you have it. Loss vs. learning rate. From that its easy to choose an appropiate learning rate.

But this only, impressive as it can be,   would not have motivated me to post on the subject. What I found promising is the possibility of using this tool  to visualize the famous relationship between learning rate and batch size.

For the ones anaware, general rule is "bigger batch size bigger learning rate". This is just logical because bigger batch size means more confidence in the direction of your "descent" of the error surface while the smaller a batch size is the closer you are to "stochastic" descent (batch size 1), that also works but where direction of individual "steps" is more... well, more stochastic. 

Sometimes it is true that a picture is worth one thousand words:

img src="img/learning_rate_vs_batch_size_g.PNG"


There you have it, the relationship between learning rate error plotted from batches from 64 to 8 for the "cats vs. dogs" dataset. As expected bigger batch size shows bigger optimal learning rate, but if you are like me maybe will find it nice to see this relationship visualized, the differences in the curves as well as the increasing noise of the relationship as batch size decreases.

